from collections import defaultdict
import os.path
import yaml
import random

configfile: "snakemake/config.json"

config['projects'] = yaml.load(open("./projects.yaml",'r'))
config['seeds'] = range(config['NSEED'])
print(config['seeds'])

rule all:
    input:
        expand("re/{project}/{project}.hc_sets.genes.txt",project=['ov']),

rule index_to_id:
    input:
        're/{project}/{project}.hc_sets.txt',
        lambda wildcards: config['projects'][wildcards.project]
    output:
        're/{project}/{project}.hc_sets.genes.txt'
    singularity:
        "docker://merckey/hotpot:mescan-1.0.0"
    shell:
        "Rscript snakemake/scripts/index2gene.R {input[1]} {input[0]}"
rule hc_sets:
    input:
        merged = expand("re/{{project}}/comb/gs{size}.merge.txt", size = range(2,6)),
        cutoff = 're/{project}/cutoff.1e5.txt'
    output:
        're/{project}/{project}.hc_sets.txt'
    shell:
        "python snakemake/scripts/detect_multi_sets_jaccard.py "
        "{output} re/{wildcards.project}/comb/ "
        "{input.cutoff} > hc_sets.log"


rule combine_seeds:
    input:
        expand("re/{{project}}/freq/gs{{size}}.s{seed}.freq",seed=config['seeds'])
    output:
        "re/{project}/comb/gs{size}.merge.txt"
    params:
        cutoff = lambda wildcards: get_cutoff(wildcards)
    shell:
        "python snakemake/scripts/mergeFreq.py "
        "re/{wildcards.project} {params.cutoff} {wildcards.size}"

rule collapse_sets:
    input:
        "re/{project}/raw/gs{size}.s{seed}.raw"
    output:
        "re/{project}/freq/gs{size}.s{seed}.freq"
    threads:
        config['NSEED']
    shell:
        "python snakemake/scripts/geneset_freq_single.py "
        "{input} 0 {output}"


rule MCMC:
    input:
        tn = "re/{project}/tunning.txt",
        dt = lambda wildcards: config['projects'][wildcards.project]
    output:
        expand("re/{{project}}/raw/gs{{size}}.s{seed}.raw",
            seed=config['seeds'])
    threads:
        config['NSEED']
    params:
        tunning = lambda wildcards: get_tunning(wildcards)
    singularity:
        "docker://merckey/hotpot:mescan-1.0.0"
    shell:
        "Rscript snakemake/scripts/runMCMC_nseeds.R "
        "{input.dt} "
        "{wildcards.size} "
        "{config[NUM_ITERS]} "
        "{params.tunning} "
        "{config[BURNING]} "
        "{config[NSEED]} "
        "re/{wildcards.project}"

rule estimate_FDRcutoff:
    input:
        lambda wildcards: config['projects'][wildcards.project]
    output:
        "re/{project}/cutoff.{iter,[^.]+}.txt"
    threads:
        1
    singularity:
        "docker://merckey/hotpot:mescan-1.0.0"
    shell:
        "Rscript snakemake/scripts/get_threshold.R "
        "{input} 2 5 {output} {wildcards.iter} 15"

rule find_tunning:
    input:
        lambda wildcards: config['projects'][wildcards.project]
    output:
        "re/{project}/tunning.txt"
    singularity:
        "docker://merckey/hotpot:mescan-1.0.0"
    shell:
        "Rscript snakemake/scripts/get_tunning.R {input} "
        "2 5 "
        "100000 "
        "1 > {output}"


def get_tunning(wildcards):
    fname = "re/"+wildcards.project+"/tunning.txt"
    if not os.path.isfile(fname):
        return(0)
    t = dict()
    with open(fname,'r') as fi:
        for i in fi:
            cols = i.strip().split(' ')
            t[cols[0]] = cols[1]
    return(t[wildcards.size])

def get_cutoff(wildcards):
    fname = "re/"+wildcards.project+"/cutoff.txt"
    if not os.path.isfile(fname):
        return(0)
    t = dict()
    with open(fname,'r') as fi:
        for i in fi:
            cols = i.strip().split(' ')
            t[cols[0]] = cols[1]
    return(t[wildcards.size])
